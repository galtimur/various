{
    "bug_loc_paths_f1": {
        "Claude 3.5 Haiku": 0.583,
        "Claude 3.5 Sonnet": 0.523,
        "DeepSeek R1 (70B)": 0.548,
        "Gemini 1.5 Pro": 0.501,
        "GPT-3.5 Turbo (1106)": 0.421,
        "GPT-4o": 0.527,
        "GPT-4o mini": 0.416,
        "Llama-3.1 (70B)": 0.351,
        "Llama-3.1 (8B)": 0.305,
        "Llama-3.2 (3B)": 0.321,
        "o1": 0.576,
        "Qwen2 (72B)": 0.483,
        "Qwen2.5 (7B)": 0.517
    },
    "CI_builr_repair": {
        "Claude-3.5-Sonnet": 24,
        "Claude-3-Haiku": 2,
        "Claude-3-Opus": 14,
        "DeepSeek-R1": 23,
        "Gemini-pro-1.5": 10,
        "GPT-4o": 10,
        "Llama-3.1-405B": 4,
        "Llama-3.1-70B": 5,
        "Llama-3.1-8B": 0
    },
    "cmg": {
        "Claude 3 Haiku": 5.045,
        "Claude 3 Opus": 7.656,
        "Claude 3.5 Sonnet": 6.134,
        "CodeLLaMA (13B)": 3.642,
        "CodeLLaMA (34B)": 3.684,
        "CodeLLaMA (7B)": 2.807,
        "CodeT5 (220M)": 2.633,
        "DeepSeek Coder (1.3B)": 2.029,
        "DeepSeek Coder (33B)": 4.471,
        "DeepSeek Coder (6.7B)": 3.604,
        "DeepSeek-R1 (671B)": 5.94,
        "DeepSeek-V3 (671B)": 6.599,
        "Gemini 1.5 Flash": 5.865,
        "Gemini 1.5 Pro": 6.363,
        "GPT-3.5 Turbo (0613)": 4.227,
        "GPT-3.5 Turbo (1106)": 3.815,
        "GPT-4 (0613)": 5.217,
        "GPT-4 Turbo (1106)": 5.296,
        "GPT-4o (2024-11-20)": 5.548,
        "GPT-4o mini (2024-07-18)": 5.158,
        "Llama-3.1 (405B)": 6.516,
        "Llama-3.1 (70B)": 6.626,
        "Llama-3.1 (8B)": 4.768,
        "Llama-3.2 (3B)": 4.102,
        "Llama-3.3 (70B)": 6.415,
        "Mistral (7B)": 4.458,
        "Mixtral 8 bit (8x7B)": 5.376,
        "o1-mini (2024-09-12)": 6.712,
        "o1-preview (2024-09-12)": 7.66,
        "Qwen2.5-Coder (32B)": 6.038,
        "QwQ (32B)": 3.381
    },
    "lib_code_gen_200": {
        "Claude-3.5-Haiku": 0.37,
        "Claude-3.5-Sonnet": 0.47,
        "Claude-3-Opus": 0.46,
        "GPT-3.5-turbo": 0.23,
        "GPT-4": 0.4,
        "GPT-4o": 0.4,
        "gpt-4o-mini": 0.31,
        "Llama-3-70B": 0.32,
        "Llama-3-8B": 0.14,
        "Mistral-7B": 0.2,
        "Mixtral-8x7B": 0.19,
        "o1": 0.36,
        "o1-mini": 0.32,
        "Qwen2.5-Coder-32B": 0.38
    },
    "module_sum": {
        "CodeLlama-70B": 37.23,
        "CodeLlama-7B": 38.06,
        "deepseek-ai-DeepSeek-R1": 64.87,
        "deepseek-ai-DeepSeek-V3": 66.37,
        "Gemma-2B": 25.38,
        "Gemma-7B": 33.96,
        "GPT-3.5": 49.48,
        "GPT-4": 57.33,
        "gpt-4o": 65.95,
        "Llama2-13B": 48.12,
        "Llama2-70B": 48.24,
        "Llama2-7B": 46.19,
        "Llama3.3-Instruct": 59.67,
        "Llama3-70B": 36.45,
        "Llama3-8B": 37.35,
        "Mistral-7B-v0.3": 46.23,
        "Mixtral-8x22B": 42.24,
        "Mixtral-8x7B": 40.89,
        "o1": 66.33,
        "Qwen2.5-72B-Instruct": 66.37
    },
    "plcc_proj_lev_path_dist_em": {
        "Codellama-7b-hf": 0.43,
        "deepseek-coder-1.3b-base": 0.38,
        "deepseek-coder-33b-base": 0.46,
        "deepseek-coder-6.7b-base": 0.43,
        "Llama-3.1-8b": 0.43,
        "Llama-3.2-1b": 0.35,
        "Llama-3.2-3b": 0.39,
        "Qwen2.5-Coder-0.5B": 0.37,
        "Qwen2.5-Coder-1.5B": 0.4,
        "Qwen2.5-Coder-14B": 0.48,
        "Qwen2.5-Coder-32B": 0.49,
        "Qwen2.5-Coder-3B": 0.43,
        "Qwen2.5-Coder-7B": 0.45
    }
}