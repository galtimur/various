{
    "bug_loc_paths_f1": {
        "Claude-3.5 Haiku": 0.583,
        "Claude-3.5 Sonnet": 0.523,
        "DeepSeek-R1 (70B)": 0.548,
        "Gemini-1.5 Pro": 0.501,
        "GPT-3.5 turbo 1106": 0.421,
        "GPT-4o": 0.527,
        "GPT-4o mini": 0.416,
        "Llama-3.1 (70B)": 0.351,
        "Llama-3.1 (8B)": 0.305,
        "Llama-3.2 (3B)": 0.321,
        "GPT-o1": 0.576,
        "Qwen-2 (72B)": 0.483,
        "Qwen-2.5 (7B)": 0.517
    },
    "CI_builr_repair": {
        "Claude-3.5 Sonnet": 24,
        "Claude-3 Haiku": 2,
        "Claude-3 Opus": 14,
        "DeepSeek-R1 (671B)": 23,
        "Gemini-1.5 Pro": 10,
        "GPT-4o": 10,
        "Llama-3.1 (405B)": 4,
        "Llama-3.1 (70B)": 5,
        "Llama-3.1 (8B)": 0
    },
    "cmg": {
        "Claude-3 Haiku": 5.045,
        "Claude-3 Opus": 7.656,
        "Claude-3.5 Sonnet": 6.134,
        "CodeLlama (13B)": 3.642,
        "CodeLlama (34B)": 3.684,
        "CodeLlama (7B)": 2.807,
        "CodeT5 (220M)": 2.633,
        "DeepSeek coder (1.3B)": 2.029,
        "DeepSeek coder (33B)": 4.471,
        "DeepSeek coder (6.7B)": 3.604,
        "DeepSeek-R1 (671B)": 5.94,
        "DeepSeek-V3 (671B)": 6.599,
        "Gemini-1.5 Flash": 5.865,
        "Gemini-1.5 Pro": 6.363,
        "GPT-3.5 turbo 0613": 4.227,
        "GPT-3.5 turbo 1106": 3.815,
        "GPT-4": 5.217,
        "GPT-4 turbo": 5.296,
        "GPT-4o": 5.548,
        "GPT-4o mini": 5.158,
        "Llama-3.1 (405B)": 6.516,
        "Llama-3.1 (70B)": 6.626,
        "Llama-3.1 (8B)": 4.768,
        "Llama-3.2 (3B)": 4.102,
        "Llama-3.3 (70B)": 6.415,
        "Mistral (7B)": 4.458,
        "Mixtral (8x7B)": 5.376,
        "GPT-4o1 mini": 6.712,
        "GPT-4o1 preview": 7.66,
        "Qwen-2.5 coder (32B)": 6.038,
        "QwQ (32B)": 3.381
    },
    "lib_code_gen_200": {
        "Claude-3.5 Haiku": 0.37,
        "Claude-3.5 Sonnet": 0.47,
        "Claude-3 Opus": 0.46,
        "GPT-3.5 turbo": 0.23,
        "GPT-4": 0.4,
        "GPT-4o": 0.4,
        "GPT-4o mini": 0.31,
        "Llama-3 (70B)": 0.32,
        "Llama-3 (8B)": 0.14,
        "Mistral (7B)": 0.2,
        "Mixtral (8x7B)": 0.19,
        "GPT-4o1": 0.36,
        "GPT-4o1 mini": 0.32,
        "Qwen-2.5 coder (32B)": 0.38
    },
    "module_sum": {
        "CodeLlama (70B)": 37.23,
        "CodeLlama (7B)": 38.06,
        "DeepSeek-R1 (671B)": 64.87,
        "DeepSeek-V3 (671B)": 66.37,
        "Gemma-2B": 25.38,
        "Gemma-7B": 33.96,
        "GPT-3.5": 49.48,
        "GPT-4": 57.33,
        "GPT-4o": 65.95,
        "Llama-2 (13B)": 48.12,
        "Llama-2 (70B)": 48.24,
        "Llama-2 (7B)": 46.19,
        "Llama-3.3 (70B)": 59.67,
        "Llama-3 (70B)": 36.45,
        "Llama-3 (8B)": 37.35,
        "Mistral (7B)": 46.23,
        "Mixtral (8x22B)": 42.24,
        "Mixtral (8x7B)": 40.89,
        "GPT-4o1": 66.33,
        "Qwen-2.5 (72B)": 66.37
    },
    "plcc_proj_lev_path_dist_em": {
        "CodeLlama (7B)": 0.43,
        "DeepSeek-Сoder (1.3B)": 0.38,
        "DeepSeek-Сoder (33B)": 0.46,
        "DeepSeek-Сoder (6.7B)": 0.43,
        "Llama-3.1 (8B)": 0.43,
        "Llama-3.2 (1B)": 0.35,
        "Llama-3.2 (3B)": 0.39,
        "Qwen-2.5 coder (0.5B)": 0.37,
        "Qwen-2.5 coder (1.5B)": 0.4,
        "Qwen-2.5 coder (14B)": 0.48,
        "Qwen-2.5 coder (32B)": 0.49,
        "Qwen-2.5 coder (3B)": 0.43,
        "Qwen-2.5 coder (7B)": 0.45
    }
}